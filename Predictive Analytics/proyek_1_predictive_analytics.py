# -*- coding: utf-8 -*-
"""Proyek 1 Predictive Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nRrk7TgEfqy0QxdNWIh_YC8_mHk4fKhO

# Prepare Datasets

Renol Nindi Kara N
"""

!pip install kaggle

!mkdir ~/.kaggle
!mkdir datasets

!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download mruanova/us-gasoline-and-diesel-retail-prices-19952021

!unzip /content/us-gasoline-and-diesel-retail-prices-19952021.zip -d datasets/

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

# load the dataset
df = pd.read_csv('/content/datasets/PET_PRI_GND_DCUS_NUS_W.csv')
df

"""# Data Understanding

•	Memberikan informasi seperti jumlah data, kondisi data, dan informasi mengenai data yang digunakan 

  •	Menuliskan tautan sumber data (link download).

  https://www.kaggle.com/datasets/mruanova/us-gasoline-and-diesel-retail-prices-19952021

  •	Menguraikan seluruh variabel atau fitur pada data.

  •	Melakukan beberapa tahapan yang diperlukan untuk memahami data contohnya teknik visualisasi data atau exploratory data analysis.

## NOTE

Information about Column:


A1: Weekly U.S. All Grades All Formulations Retail Gasoline Prices (Dollars per Gallon)

A2: Weekly U.S. All Grades Conventional Retail Gasoline Prices (Dollars per Gallon)

A3: Weekly U.S. All Grades Reformulated Retail Gasoline Prices (Dollars per Gallon)

R1: Weekly U.S. Regular All Formulations Retail Gasoline Prices (Dollars per Gallon)

R2: Weekly U.S. Regular Conventional Retail Gasoline Prices (Dollars per Gallon)

R3: Weekly U.S. Regular Reformulated Retail Gasoline Prices (Dollars per Gallon)

M1: Weekly U.S. Midgrade All Formulations Retail Gasoline Prices (Dollars per Gallon)

M2: Weekly U.S. Midgrade Conventional Retail Gasoline Prices (Dollars per Gallon)

M3: Weekly U.S. Midgrade Reformulated Retail Gasoline Prices (Dollars per Gallon)

P1: Weekly U.S. Premium All Formulations Retail Gasoline Prices (Dollars per Gallon)

P2: Weekly U.S. Premium Conventional Retail Gasoline Prices (Dollars per Gallon)

P3: Weekly U.S. Premium Reformulated Retail Gasoline Prices (Dollars per Gallon)

D1: Weekly U.S. No 2 Diesel Retail Prices (Dollars per Gallon)


### Note by ME
A, R, M, P adalah type Gasoline nya, sedangkan D adalah harga nya jadi yang akan kita prediksi adalah harga nya atau column D ini

Data ini udah Clean, dan tidak ada null total data / row nya ada sekitar 1361 (Sudah melebihi 500 Minimum Kriteria Data)
"""

df.shape

df.info()

df.describe()

"""## EDA"""

# Datanya belum bertype Date yang kolom Date jadi convert / ubah dulu
df['Date'] = pd.to_datetime(df['Date'])

df.info()

# Cek perubahan harga data dari tahun ke tahun
plt.title(f'Data dari tahun ke tahun')
plt.plot(df['Date'], df['D1'])
plt.show()

# Kita coba cek sebaran dengan cycle per tahun
year = df['Date'].dt.year
year

# Pindahin dulu ke array karena akan di loop, supaya langsung banyak grafik nya, kalau pake subplots nanti kecil kecil
year.unique()

for y in year.unique():
  plt.title(f'Tahun {y}')
  plt.plot(df[df['Date'].dt.year == y].D1)
  plt.show()

"""Setelah di Cek kayaknya ga terlalu menentu kalau kita ambil lifecycle kayak per 5 tahun, atau per 10 tahun... jadi kita akan train dari tahun 1995"""

# Cek Outliers
# Ada error ternyata harus Float sedangkan dataframe masih ada Date jadi di drop dulu
columns = np.delete(df.columns, 0)
for col in columns:
  plt.title(f'Column {col}')
  sns.boxplot(df[col])
  plt.show()

# Next Step adalah Cek Korelasi antaar Column karena Column Date gak ke pake jadi kita drop dulu
new_df = df.drop('Date', axis=1)
new_df

plt.figure(figsize=(10,10))
sns.heatmap(new_df.corr(), annot=True, cmap='coolwarm',linewidths=0.5)
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)
plt.show()

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(new_df, diag_kind = 'kde')

# Terlalu besar agak sulit dilihat
sns.pairplot(df[['A1','R1','M1', 'P1']], plot_kws={"s": 4});

# By Class of Gasoline
sns.pairplot(df[['A2','R2','M2', 'P2']], plot_kws={"s": 4});

# By Class of Gasoline
sns.pairplot(df[['A3','R3','M3','P3']], plot_kws={"s": 4});

"""# Data Preparation

•	Menerapkan dan menyebutkan teknik data preparation yang dilakukan.

•	Teknik yang digunakan pada notebook dan laporan harus berurutan.

•	Menjelaskan proses data preparation yang dilakukan

•	Menjelaskan alasan mengapa diperlukan tahapan data preparation tersebut.
"""

# Kayaknya tidak ada outliers, gas next Step dan tidak ada categorical column jadi langsung saja tidak perlu label encoder / OHE
df.head()

# Setau dan Seingat saya Scaller itu sebelum di Split, maaf kalau salah emang sepengalaman saya gitu sih thx
# Pake MinMaxScaller, nanti hasilnya 0 - 1, karena ini feature data agak ranking juga sih semakin gede semakin jelek / mahal, kalau pakai standart kayaknya range nya terlalu jauh
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

final_df = new_df
scaler.fit(final_df[final_df.columns])
final_df[final_df.columns] = scaler.transform(final_df.loc[:, final_df.columns])

final_df

final_df.describe()

# Abis di Standar tinggal di split, jadi data test tinggal tembak aja pake pred
from sklearn.model_selection import train_test_split

X, y = final_df.drop('D1', axis=1), final_df['D1']

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=767)

"""# Modelling

•	Membuat model machine learning untuk menyelesaikan permasalahan.

•	Menjelaskan tahapan dan parameter yang digunakan pada proses pemodelan.

•	Menjelaskan kelebihan dan kekurangan dari setiap algoritma yang digunakan.

•	Jika menggunakan satu algoritma pada solution statement, lakukan proses improvement terhadap model dengan hyperparameter tuning. Jelaskan proses improvement yang dilakukan.

•	Jika menggunakan dua atau lebih algoritma pada solution statement, maka pilih model terbaik sebagai solusi. Jelaskan mengapa memilih model tersebut sebagai model terbaik.

##### Ada Tips sih disini kita bisa pakai Lazy Predict agar tinggal nunggu aja hehehe abis itu tinggal pilih dah model terbaik


baca dokumentasi di https://lazypredict.readthedocs.io/en/latest/usage.html#regression
"""

# Install terlebih dahulu
!pip install lazypredict

from lazypredict.Supervised import LazyRegressor

# Declare the Function
reg = LazyRegressor(verbose=0,ignore_warnings=False, custom_metric=None )

# Train model nya ada banyak lebih dari 20 mungkin, sebenernya ini patokan aja sih, soalnya nanti gabisa dipake buat prediksi / evaluation
models,predictions = reg.fit(x_train, x_test, y_train, y_test)

models

"""## Note

Sebenernya Lazy Predict ini hanya untuk patokan saja, kita harus training lagi untuk evaluation dan test prediksi
"""

# Training 4 Model Teratas
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Siapkan dataframe untuk analisis model
report = pd.DataFrame(index=['train_mse', 'test_mse'], 
                      columns=['GradientBoosting', 'RandomForest', 'XGB', 'LGBM'])

# buat model prediksi
# n_estimator = number of tree in the forest
# max_depth = max kedalaman tree, ini hapus aja biar unlimited
# n_jobs = -1 using all processor
RF = RandomForestRegressor(n_estimators=100, random_state=55, n_jobs=-1)
RF.fit(x_train, y_train)

XGB = GradientBoostingRegressor()
XGB.fit(x_train, y_train)

LGBM = LGBMRegressor()
LGBM.fit(x_train, y_train)

GB = GradientBoostingRegressor()
GB.fit(x_train, y_train)

"""# Evaluation

•	Menyebutkan metrik evaluasi yang digunakan.

•	Menjelaskan hasil proyek berdasarkan metrik evaluasi.

•	Metrik evaluasi yang digunakan harus sesuai dengan konteks data, problem statement, dan solusi yang diinginkan.

•	Menjelaskan metrik evaluasi yang digunakan untuk mengukur kinerja model. Misalnya, menjelaskan formula metrik dan bagaimana metrik tersebut bekerja.

Metrix evaluasi yang digunakan adalah MSE / Mean Squared Error

MSE ini rumusnya 1/N dimana N adalah jumlah dataset dikali kuadrat dari actual value dikurangi predicted value atau

mse = $1 \over n$ $\sum_{n=0}^n $ $(y_i - ŷ_p) ^ 2 $ 

FYI kalau kita ingin menghitung rmse kita tinggal mengakar kan mse nya saja np.sqrt

rmse = $\sqrt{\sum\nolimits_{n=1}^n \left((y_i - ŷ_p) ^ 2 \over n \right) }$  

R2 Score dijadikan sebagai pengukuran seberapa baik garis regresi mendekati nilai data asli yang dibuat melalui model.

$r^2$ = 1 - $SS_R \over SS_T$ =  1 - $ \sum_{i} (y_i - ŷ_p) ^ 2 \over \sum_{i} (y_i - ȳ) ^ 2$

Dan sepengalaman saya untuk eval itu data test saja
"""

final_report = {'Model_Name': [], 'mse': [], 'r2': []}
pred = GB.predict(x_test)
mse = mean_squared_error(y_true=y_test, y_pred=pred)
r2 = r2_score(y_test, pred)
final_report['Model_Name'].append('GB')
final_report['mse'].append(mse)
final_report['r2'].append(r2)
pred = LGBM.predict(x_test)
mse = mean_squared_error(y_true=y_test, y_pred=pred)
r2 = r2_score(y_test, pred)
final_report['Model_Name'].append('LGBM')
final_report['mse'].append(mse)
final_report['r2'].append(r2)
pred = RF.predict(x_test)
mse = mean_squared_error(y_true=y_test, y_pred=pred)
r2 = r2_score(y_test, pred)
final_report['Model_Name'].append('RF')
final_report['mse'].append(mse)
final_report['r2'].append(r2)
pred = XGB.predict(x_test)
mse = mean_squared_error(y_true=y_test, y_pred=pred)
r2 = r2_score(y_test, pred)
final_report['Model_Name'].append('XGB')
final_report['mse'].append(mse)
final_report['r2'].append(r2)

final_report

# 0.0 nya terlalu jauh jadi di format terlebih dahulu
pd.options.display.float_format = '{:.7f}'.format

final_report = pd.DataFrame.from_dict(final_report)
final_report

final_report['rmse'] = np.sqrt(final_report['mse'])

final_report

# GB sama RF sama mse, rmse, r2 nya
model_dict = {'RF': RF, 'XGB': XGB, 'GB': GB, 'LGBM': LGBM}
prediksi = x_test.iloc[:120].copy()
pred_dict = {'y_true':y_test[:120]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)
 
pd.DataFrame(pred_dict)